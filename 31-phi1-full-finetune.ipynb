{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa45d2-01fa-4118-81f1-aaca7a53edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d0497-7216-4760-89f9-ff9398f624ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Hyper-parameters\n",
    "###################\n",
    "args = {\n",
    "    \"bf16\": True,\n",
    "    \"do_eval\": False,\n",
    "    \"learning_rate\": 5.0e-06,\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_steps\": 20,\n",
    "    \"logging_strategy\": \"steps\",\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_train_epochs\": 10,\n",
    "    \"max_steps\": -1,\n",
    "    \"output_dir\": \"phi1-ai-abstracts\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"per_device_eval_batch_size\": 1,\n",
    "    \"per_device_train_batch_size\": 1,\n",
    "    \"remove_unused_columns\": True,\n",
    "    \"save_steps\": 100000000000000,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"gradient_checkpointing_kwargs\":{\"use_reentrant\": False},\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"warmup_ratio\": 0.2,\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acbd904-215d-4444-a2ad-74decb3e8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Model Loading\n",
    "################\n",
    "checkpoint_path = \"microsoft/Phi-1.5\"\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation=\"flash_attention_2\",  # loading the model with flash-attention support\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda:0\",\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "tokenizer.pad_token = tokenizer.unk_token  # use unk rather than eos token to prevent endless generation\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f0aab7-8c77-47c6-a556-360b22859b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Data Processing\n",
    "##################\n",
    "phi3_prompt = \"\"\"<|system|>\n",
    "You are an educated researcher and always answer in correct scientific terms.\n",
    "<|end|>\n",
    "<|user|>\n",
    "Write an abstract for \"{}\"\n",
    "<|end|>\n",
    "<|assistant|>\n",
    "Abstract:\n",
    "\n",
    "{}\n",
    "<|end|>\"\"\"\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    titles    = examples[\"title\"]\n",
    "    abstracts = examples[\"abstract\"]\n",
    "    texts = []\n",
    "    for title, abstract in zip(titles,  abstracts):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = phi3_prompt.format(title, abstract)\n",
    "        texts.append(text)\n",
    "\n",
    "    # first instruction should start with system prompt?\n",
    "    return { \"text\" : texts, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd6f015-e76d-4a18-9731-b63c5acd7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"ai-abstracts.jsonl.xz\", split=\"train\")\n",
    "train_dataset = dataset.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc881e45-cbf4-48b7-b26c-0288e6a4abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Training\n",
    "###########\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    processing_class=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73764c-7fca-4ac8-9b77-093615f45b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106719e-9e89-417c-939b-83dcaf37da5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1856567b-9039-48a8-85d2-0cf202960c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f870b1-0635-48f0-8cfb-a22209db789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(training_args.output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
